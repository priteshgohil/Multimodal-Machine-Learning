{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f929e73e7fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     trainer = Run_Model(root = args.root, mode = args.mode, test_dir=args.test_dir,\n\u001b[0m\u001b[1;32m    204\u001b[0m                        \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model_withname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                        save_error_withname = args.save_error, checkpoint=args.checkpoint)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'root'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1,2,3'\n",
    "import sys\n",
    "import argparse\n",
    "import tensorboardX\n",
    "import videotransforms\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from datasetv1 import VisualTactile\n",
    "from fusionNet import FusionNet\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import resnet\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-root', required=True, type=str, help = 'dataset path')\n",
    "parser.add_argument('-mode', required=True, type=str, help='specify train or test')\n",
    "parser.add_argument('-test_dir', required=True, type=str, help = 'test.txt file path')\n",
    "parser.add_argument('-train_dir', required=True, type=str, help = 'train.txt file path')\n",
    "parser.add_argument('-save_model',required=False, type=str, help='enter the name you would like to save model with')\n",
    "parser.add_argument('-save_error', required=True, type=str)\n",
    "parser.add_argument('-checkpoint', required=False, type=str, help='path to saved model')\n",
    "\n",
    "args = parser.parse_args\n",
    "\n",
    "class Run_Model(object):\n",
    "    \n",
    "    def __init__(self, root, mode, test_dir, train_dir, save_model_withname=None,\\\n",
    "                 save_error_withname=None, checkpoint=None):\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.test_dir = test_dir\n",
    "        self.train_dir = train_dir\n",
    "        self.save_model_withname = save_model_withname\n",
    "        self.save_error_withname = save_error_withname\n",
    "        self.checkpoint = checkpoint\n",
    "        self.batch_size = 1\n",
    "        self.learning_rate = 0.0001\n",
    "        \n",
    "        if(self.mode=='train'):\n",
    "            self.writer = tensorboardX.SummaryWriter(comment=self.save_error_withname)\n",
    "        else:\n",
    "            self.writer = tensorboardX.SummaryWriter(comment=\"test\")\n",
    "        # setup dataset\n",
    "        self.train_transforms = transforms.Compose([videotransforms.RandomCrop(112),\n",
    "                                           videotransforms.RandomHorizontalFlip(),])\n",
    "        self.test_transforms = transforms.Compose([videotransforms.CenterCrop(112)])\n",
    "            \n",
    "        self.dataset = VisualTactile(self.root, self.train_dir, self.train_transforms)\n",
    "        self.dataloader = torch.utils.data.DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "                \n",
    "        self.val_dataset = VisualTactile(self.root, self.test_dir, self.test_transforms)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(self.val_dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "        \n",
    "#         self.dataloaders = {'train': self.dataloader, 'val': self.val_dataloader}\n",
    "#         self.datasets = {'train': self.dataset, 'val': self.val_dataset}\n",
    "        \n",
    "        self.model, self.optimizer, self.scheduler = self.load_model(self.checkpoint)\n",
    "        \n",
    "    def load_model(self, checkpoint):\n",
    "        sm = resnet.resnet18(sample_size = 112, sample_duration = 18, num_classes = 400, shortcut_type='A')\n",
    "        sm = nn.DataParallel(sm)\n",
    "        if torch.cuda.is_available():\n",
    "            pretrain = torch.load(\"../models/resnet-18-kinetics.pth\")\n",
    "            sm.load_state_dict(pretrain['state_dict'])\n",
    "        else: \n",
    "#             pretrain = torch.load(\"../models/resnet-18-kinetics.pth\", map_location=\"cpu\")\n",
    "            pretrain = torch.load(\"../../../out/resnet/resnet-18-kinetics.pth\", map_location=\"cpu\")\n",
    "            sm.load_state_dict(pretrain['state_dict'])\n",
    "        sm = self.freeze_network_layer(sm)\n",
    "        \n",
    "        net = FusionNet(sm)\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "            net = nn.DataParallel(net)\n",
    "        optimizer = optim.Adam(net.parameters(), lr=self.learning_rate, weight_decay=0.0000001)\n",
    "        lr_sched = optim.lr_scheduler.MultiStepLR(optimizer, [10, 20, 25])\n",
    "        \n",
    "        #checkpoint in case of training\n",
    "        if (checkpoint is not None):\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(checkpoint)\n",
    "            else:\n",
    "                data = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "            net.load_state_dict(data['model_state'])\n",
    "            optimizer.load_state_dict(data['optimizer_state'])\n",
    "            lr_sched.load_state_dict(data['scheduler_state'])\n",
    "        return net, optimizer, lr_sched\n",
    "    \n",
    "    def freeze_network_layer(self, model):\n",
    "        for para in model.parameters():\n",
    "            para.requires_grad = False\n",
    "        return model\n",
    "\n",
    "    def save_checkpoint(self, model, optimizer, scheduler, epoch, save_model):\n",
    "        data = {'model_state' : model.state_dict(),\n",
    "                'optimizer_state' : optimizer.state_dict(),\n",
    "                'scheduler_state' : scheduler.state_dict(),\n",
    "                'epoch' : epoch+1}\n",
    "        torch.save(data, 'model_%d' %(epoch + 1) +save_model + '.tar' )\n",
    "        \n",
    "    def train(self):\n",
    "        with open(self.save_error_withname, 'w') as file:\n",
    "            file.write(\"train loss file\\n\")\n",
    "        epoch_num = 30\n",
    "        self.model.train(True)\n",
    "        for epoch in range(epoch_num):\n",
    "            print ('Step {}/{}'.format(epoch, epoch_num))\n",
    "            print ('-' * 10)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            total_loss = 0\n",
    "            for i,data in enumerate(self.dataloader):\n",
    "                vid, lab = data\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    video = Variable(vid.cuda())\n",
    "                    label = Variable(lab.cuda())\n",
    "                else:\n",
    "                    video = Variable(vid)\n",
    "                    label = Variable(lab)\n",
    "                \n",
    "                out = self.model(video.float())\n",
    "                out = out.squeeze(1)\n",
    "                loss = F.binary_cross_entropy_with_logits(out.float(), label.float())\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                print('{} Loss: {:.4f} and lr: {}'.format(self.mode,total_loss/(i+1),self.scheduler.get_lr()[0]))\n",
    "                with open(self.save_error_withname, 'a') as file:\n",
    "                    file.write(\"epoch: {}, Loss: {}\".format(epoch, total_loss/(i+1)))\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                self.writer.add_scalar(\"error/{}\".format(epoch), total_loss/(i+1), i)\n",
    "            self.writer.add_scalar(\"errorPerEpoch/{}\".format(epoch), total_loss/(i+1), epoch)\n",
    "            self.scheduler.step()\n",
    "            if((epoch+1)%30 == 0):\n",
    "                self.save_checkpoint(self.model, self.optimizer, self.scheduler, epoch, self.save_model_withname)\n",
    "        \n",
    "        \n",
    "    def test(self):\n",
    "        with open(self.save_error_withname, 'w') as file:\n",
    "            file.write(\"test loss file\\n\")\n",
    "        self.model.train(False)\n",
    "        test_TP,test_TN,test_FP,test_FN= 0,0,0,0\n",
    "        actual_out, predicted_out = 0,0\n",
    "        video_num = self.val_dataset.get_num_videos()\n",
    "        count = 0\n",
    "        for index in range(video_num):\n",
    "            data = self.val_dataset.get_video_frames(index)\n",
    "            packed_data, vid_path = data\n",
    "            print(\"directory: {}\".format(vid_path))\n",
    "            # iterating though mini clips in a video\n",
    "            for i,dota in enumerate(packed_data):\n",
    "                video, label = dota\n",
    "                label = label.unsqueeze(0) #because without this its shape is empty\n",
    "                if torch.cuda.is_available():\n",
    "                    video = Variable(video.cuda())\n",
    "                    label = Variable(label.cuda())\n",
    "                else:\n",
    "                    video = Variable(video)\n",
    "                    label = Variable(label)\n",
    "                video = video.unsqueeze(0)\n",
    "                out = self.model(video.float())\n",
    "                print(out.shape, label)\n",
    "                out = out.squeeze(1)\n",
    "                print(out.shape, type(label))\n",
    "                loss = F.binary_cross_entropy_with_logits(out.float(), label.float())\n",
    "                actual_out = label[0]\n",
    "                predicted_out = 1 if out[0]>0 else 0\n",
    "                print('{}: Loss: {:.5f} and lr: {:.5f}.... Network output: {:.5f} and actual label: {} '.format(i,loss.item(),self.scheduler.get_lr()[0],out[0], label[0]))\n",
    "                with open(self.save_error_withname, 'a') as file:\n",
    "                    file.write('{}: Loss: {:.5f} and lr: {:.5f}.... Network output: {:.5f} and actual label: {} '.format(i,loss.item(),self.scheduler.get_lr()[0],out[0], label[0]))\n",
    "                self.writer.add_scalar('inference_error/{}'.format(index), loss.item(), i)\n",
    "                self.writer.add_scalar('combined_inference_error', loss.item(), count)\n",
    "                count += 1\n",
    "                \n",
    "                if actual_out == predicted_out:\n",
    "                    if actual_out:\n",
    "                        test_TP +=1\n",
    "                    else:\n",
    "                        test_TN +=1\n",
    "                else:\n",
    "                    if actual_out:\n",
    "                        test_FN +=1\n",
    "                    else:\n",
    "                        test_FP +=1\n",
    "        with open(self.save_error_withname, 'a') as file:\n",
    "            file.write(\"-\"*100)\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"Network information\\n\")\n",
    "            file.write(\"learning rate: {}, batch size: {}, saved model name: {}, optimizer : Adam, learning steps: [10,20,25] \\n\".format(self.learning_rate,self.save_model_withname))\n",
    "            file.write(\"-\"*100)\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"Confusion matrix for test data \\n\")\n",
    "            file.write(\"TP: {}, TN: {}, FP: {}, FN: {} \\n\".format(test_TP, test_TN, test_FP, test_FN))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    trainer = Run_Model(root = args.root, mode = args.mode, test_dir=args.test_dir,\n",
    "                       train_dir = agrs.train_dir, save_model_withname=args.save_model,\n",
    "                       save_error_withname = args.save_error, checkpoint=args.checkpoint)\n",
    "    \n",
    "    if(args.mode == 'train'):\n",
    "        trainer.train()\n",
    "    else:\n",
    "        trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pritesh/Entertainment/RnD/code/resnet/resnet.py:146: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "a = Run_Model(\"../../../t/Visual-Tactile_Dataset/dataset/\",\"train\",\"dummy_test.txt\",\"dummy_train.txt\",save_error_withname=\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.save_checkpoint(a.model,a.optimizer,a.scheduler,10,\"pxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.model.train(True)\n",
    "a.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,(frame,label) in enumerate(a.dataloader):\n",
    "    print(frame.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "videos = a.val_dataset.get_num_videos()\n",
    "for i in range(videos):\n",
    "    data = a.val_dataset.get_video_frames(i)\n",
    "    break\n",
    "    \n",
    "frames,path = data\n",
    "for frame in frames: \n",
    "    vid, label = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = tensorboardX.SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "writer.add_scalar(\"data/{}\".format(a), 100, 1)\n",
    "writer.add_scalar(\"data/{}\".format(a), 55, 2)\n",
    "a += 1\n",
    "writer.add_scalar(\"data/{}\".format(a), 10, 1)\n",
    "writer.add_scalar(\"data/{}\".format(a), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = torch.tensor(1,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/30\n",
      "----------\n",
      "train Loss: 0.9339 and lr: 0.0001\n",
      "train Loss: 0.8324 and lr: 0.0001\n",
      "train Loss: 0.7980 and lr: 0.0001\n",
      "train Loss: 0.7815 and lr: 0.0001\n",
      "train Loss: 0.7679 and lr: 0.0001\n",
      "train Loss: 0.7630 and lr: 0.0001\n",
      "train Loss: 0.7667 and lr: 0.0001\n",
      "train Loss: 0.7656 and lr: 0.0001\n",
      "train Loss: 0.7618 and lr: 0.0001\n",
      "train Loss: 0.7564 and lr: 0.0001\n",
      "train Loss: 0.7501 and lr: 0.0001\n",
      "train Loss: 0.7405 and lr: 0.0001\n",
      "train Loss: 0.7320 and lr: 0.0001\n",
      "train Loss: 0.7316 and lr: 0.0001\n",
      "train Loss: 0.7380 and lr: 0.0001\n",
      "train Loss: 0.7330 and lr: 0.0001\n",
      "train Loss: 0.7359 and lr: 0.0001\n",
      "train Loss: 0.7334 and lr: 0.0001\n",
      "train Loss: 0.7274 and lr: 0.0001\n",
      "train Loss: 0.7253 and lr: 0.0001\n",
      "train Loss: 0.7184 and lr: 0.0001\n",
      "train Loss: 0.7163 and lr: 0.0001\n",
      "train Loss: 0.7122 and lr: 0.0001\n",
      "train Loss: 0.7136 and lr: 0.0001\n",
      "train Loss: 0.7094 and lr: 0.0001\n",
      "train Loss: 0.7127 and lr: 0.0001\n",
      "train Loss: 0.7162 and lr: 0.0001\n",
      "train Loss: 0.7142 and lr: 0.0001\n",
      "train Loss: 0.7194 and lr: 0.0001\n",
      "train Loss: 0.7116 and lr: 0.0001\n",
      "train Loss: 0.7186 and lr: 0.0001\n",
      "train Loss: 0.7244 and lr: 0.0001\n",
      "train Loss: 0.7201 and lr: 0.0001\n",
      "train Loss: 0.7210 and lr: 0.0001\n",
      "train Loss: 0.7184 and lr: 0.0001\n",
      "train Loss: 0.7175 and lr: 0.0001\n",
      "train Loss: 0.7154 and lr: 0.0001\n",
      "train Loss: 0.7193 and lr: 0.0001\n",
      "train Loss: 0.7176 and lr: 0.0001\n",
      "train Loss: 0.7156 and lr: 0.0001\n",
      "train Loss: 0.7145 and lr: 0.0001\n",
      "train Loss: 0.7148 and lr: 0.0001\n",
      "train Loss: 0.7152 and lr: 0.0001\n",
      "train Loss: 0.7174 and lr: 0.0001\n",
      "train Loss: 0.7178 and lr: 0.0001\n",
      "train Loss: 0.7170 and lr: 0.0001\n",
      "train Loss: 0.7130 and lr: 0.0001\n",
      "train Loss: 0.7130 and lr: 0.0001\n",
      "train Loss: 0.7104 and lr: 0.0001\n",
      "train Loss: 0.7068 and lr: 0.0001\n",
      "train Loss: 0.7078 and lr: 0.0001\n",
      "train Loss: 0.7048 and lr: 0.0001\n",
      "train Loss: 0.7061 and lr: 0.0001\n",
      "train Loss: 0.7047 and lr: 0.0001\n",
      "train Loss: 0.7078 and lr: 0.0001\n",
      "Step 1/30\n",
      "----------\n",
      "train Loss: 0.5452 and lr: 0.0001\n",
      "train Loss: 0.5930 and lr: 0.0001\n",
      "train Loss: 0.6093 and lr: 0.0001\n",
      "train Loss: 0.6446 and lr: 0.0001\n",
      "train Loss: 0.6489 and lr: 0.0001\n",
      "train Loss: 0.6405 and lr: 0.0001\n",
      "train Loss: 0.6467 and lr: 0.0001\n",
      "train Loss: 0.6568 and lr: 0.0001\n",
      "train Loss: 0.6825 and lr: 0.0001\n",
      "train Loss: 0.6616 and lr: 0.0001\n",
      "train Loss: 0.6691 and lr: 0.0001\n",
      "train Loss: 0.6640 and lr: 0.0001\n",
      "train Loss: 0.6509 and lr: 0.0001\n",
      "train Loss: 0.6436 and lr: 0.0001\n",
      "train Loss: 0.6309 and lr: 0.0001\n",
      "train Loss: 0.6267 and lr: 0.0001\n",
      "train Loss: 0.6248 and lr: 0.0001\n",
      "train Loss: 0.6391 and lr: 0.0001\n",
      "train Loss: 0.6513 and lr: 0.0001\n",
      "train Loss: 0.6544 and lr: 0.0001\n",
      "train Loss: 0.6588 and lr: 0.0001\n",
      "train Loss: 0.6578 and lr: 0.0001\n",
      "train Loss: 0.6601 and lr: 0.0001\n",
      "train Loss: 0.6556 and lr: 0.0001\n",
      "train Loss: 0.6564 and lr: 0.0001\n",
      "train Loss: 0.6569 and lr: 0.0001\n",
      "train Loss: 0.6523 and lr: 0.0001\n",
      "train Loss: 0.6580 and lr: 0.0001\n",
      "train Loss: 0.6600 and lr: 0.0001\n",
      "train Loss: 0.6670 and lr: 0.0001\n",
      "train Loss: 0.6655 and lr: 0.0001\n",
      "train Loss: 0.6783 and lr: 0.0001\n",
      "train Loss: 0.6759 and lr: 0.0001\n",
      "train Loss: 0.6785 and lr: 0.0001\n",
      "train Loss: 0.6774 and lr: 0.0001\n",
      "train Loss: 0.6751 and lr: 0.0001\n",
      "train Loss: 0.6707 and lr: 0.0001\n",
      "train Loss: 0.6676 and lr: 0.0001\n",
      "train Loss: 0.6743 and lr: 0.0001\n",
      "train Loss: 0.6705 and lr: 0.0001\n",
      "train Loss: 0.6709 and lr: 0.0001\n",
      "train Loss: 0.6714 and lr: 0.0001\n",
      "train Loss: 0.6782 and lr: 0.0001\n",
      "train Loss: 0.6786 and lr: 0.0001\n",
      "train Loss: 0.6776 and lr: 0.0001\n",
      "train Loss: 0.6726 and lr: 0.0001\n",
      "train Loss: 0.6719 and lr: 0.0001\n",
      "train Loss: 0.6699 and lr: 0.0001\n",
      "train Loss: 0.6687 and lr: 0.0001\n",
      "train Loss: 0.6779 and lr: 0.0001\n",
      "train Loss: 0.6756 and lr: 0.0001\n",
      "train Loss: 0.6758 and lr: 0.0001\n",
      "train Loss: 0.6822 and lr: 0.0001\n",
      "train Loss: 0.6782 and lr: 0.0001\n",
      "train Loss: 0.6807 and lr: 0.0001\n",
      "Step 2/30\n",
      "----------\n",
      "train Loss: 1.0443 and lr: 0.0001\n",
      "train Loss: 0.7768 and lr: 0.0001\n",
      "train Loss: 0.6760 and lr: 0.0001\n",
      "train Loss: 0.6374 and lr: 0.0001\n",
      "train Loss: 0.6239 and lr: 0.0001\n",
      "train Loss: 0.6456 and lr: 0.0001\n",
      "train Loss: 0.6251 and lr: 0.0001\n",
      "train Loss: 0.6454 and lr: 0.0001\n",
      "train Loss: 0.6270 and lr: 0.0001\n",
      "train Loss: 0.6126 and lr: 0.0001\n",
      "train Loss: 0.6102 and lr: 0.0001\n",
      "train Loss: 0.6357 and lr: 0.0001\n",
      "train Loss: 0.6283 and lr: 0.0001\n",
      "train Loss: 0.6238 and lr: 0.0001\n",
      "train Loss: 0.6459 and lr: 0.0001\n",
      "train Loss: 0.6427 and lr: 0.0001\n",
      "train Loss: 0.6348 and lr: 0.0001\n",
      "train Loss: 0.6468 and lr: 0.0001\n",
      "train Loss: 0.6374 and lr: 0.0001\n",
      "train Loss: 0.6287 and lr: 0.0001\n",
      "train Loss: 0.6404 and lr: 0.0001\n",
      "train Loss: 0.6599 and lr: 0.0001\n",
      "train Loss: 0.6618 and lr: 0.0001\n",
      "train Loss: 0.6514 and lr: 0.0001\n",
      "train Loss: 0.6587 and lr: 0.0001\n",
      "train Loss: 0.6525 and lr: 0.0001\n",
      "train Loss: 0.6501 and lr: 0.0001\n",
      "train Loss: 0.6450 and lr: 0.0001\n",
      "train Loss: 0.6594 and lr: 0.0001\n",
      "train Loss: 0.6500 and lr: 0.0001\n",
      "train Loss: 0.6410 and lr: 0.0001\n",
      "train Loss: 0.6499 and lr: 0.0001\n",
      "train Loss: 0.6596 and lr: 0.0001\n",
      "train Loss: 0.6524 and lr: 0.0001\n",
      "train Loss: 0.6467 and lr: 0.0001\n",
      "train Loss: 0.6460 and lr: 0.0001\n",
      "train Loss: 0.6573 and lr: 0.0001\n",
      "train Loss: 0.6523 and lr: 0.0001\n",
      "train Loss: 0.6490 and lr: 0.0001\n",
      "train Loss: 0.6577 and lr: 0.0001\n",
      "train Loss: 0.6528 and lr: 0.0001\n",
      "train Loss: 0.6498 and lr: 0.0001\n",
      "train Loss: 0.6472 and lr: 0.0001\n",
      "train Loss: 0.6465 and lr: 0.0001\n",
      "train Loss: 0.6480 and lr: 0.0001\n",
      "train Loss: 0.6464 and lr: 0.0001\n",
      "train Loss: 0.6447 and lr: 0.0001\n",
      "train Loss: 0.6434 and lr: 0.0001\n",
      "train Loss: 0.6494 and lr: 0.0001\n",
      "train Loss: 0.6590 and lr: 0.0001\n",
      "train Loss: 0.6558 and lr: 0.0001\n",
      "train Loss: 0.6608 and lr: 0.0001\n",
      "train Loss: 0.6562 and lr: 0.0001\n",
      "train Loss: 0.6636 and lr: 0.0001\n",
      "train Loss: 0.6674 and lr: 0.0001\n",
      "Step 3/30\n",
      "----------\n",
      "train Loss: 0.4427 and lr: 0.0001\n",
      "train Loss: 0.6827 and lr: 0.0001\n",
      "train Loss: 0.7234 and lr: 0.0001\n",
      "train Loss: 0.7794 and lr: 0.0001\n",
      "train Loss: 0.7314 and lr: 0.0001\n",
      "train Loss: 0.6906 and lr: 0.0001\n",
      "train Loss: 0.6636 and lr: 0.0001\n",
      "train Loss: 0.6520 and lr: 0.0001\n",
      "train Loss: 0.6343 and lr: 0.0001\n",
      "train Loss: 0.6511 and lr: 0.0001\n",
      "train Loss: 0.6508 and lr: 0.0001\n",
      "train Loss: 0.6374 and lr: 0.0001\n",
      "train Loss: 0.6263 and lr: 0.0001\n",
      "train Loss: 0.6483 and lr: 0.0001\n",
      "train Loss: 0.6291 and lr: 0.0001\n",
      "train Loss: 0.6296 and lr: 0.0001\n",
      "train Loss: 0.6531 and lr: 0.0001\n",
      "train Loss: 0.6654 and lr: 0.0001\n",
      "train Loss: 0.6509 and lr: 0.0001\n",
      "train Loss: 0.6410 and lr: 0.0001\n",
      "train Loss: 0.6502 and lr: 0.0001\n",
      "train Loss: 0.6581 and lr: 0.0001\n",
      "train Loss: 0.6502 and lr: 0.0001\n",
      "train Loss: 0.6470 and lr: 0.0001\n",
      "train Loss: 0.6410 and lr: 0.0001\n",
      "train Loss: 0.6376 and lr: 0.0001\n",
      "train Loss: 0.6466 and lr: 0.0001\n",
      "train Loss: 0.6557 and lr: 0.0001\n",
      "train Loss: 0.6723 and lr: 0.0001\n",
      "train Loss: 0.6637 and lr: 0.0001\n",
      "train Loss: 0.6562 and lr: 0.0001\n",
      "train Loss: 0.6613 and lr: 0.0001\n",
      "train Loss: 0.6577 and lr: 0.0001\n",
      "train Loss: 0.6530 and lr: 0.0001\n",
      "train Loss: 0.6494 and lr: 0.0001\n",
      "train Loss: 0.6578 and lr: 0.0001\n",
      "train Loss: 0.6509 and lr: 0.0001\n",
      "train Loss: 0.6468 and lr: 0.0001\n",
      "train Loss: 0.6492 and lr: 0.0001\n",
      "train Loss: 0.6462 and lr: 0.0001\n",
      "train Loss: 0.6416 and lr: 0.0001\n",
      "train Loss: 0.6373 and lr: 0.0001\n",
      "train Loss: 0.6320 and lr: 0.0001\n",
      "train Loss: 0.6312 and lr: 0.0001\n",
      "train Loss: 0.6274 and lr: 0.0001\n",
      "train Loss: 0.6345 and lr: 0.0001\n",
      "train Loss: 0.6369 and lr: 0.0001\n",
      "train Loss: 0.6351 and lr: 0.0001\n",
      "train Loss: 0.6320 and lr: 0.0001\n",
      "train Loss: 0.6335 and lr: 0.0001\n",
      "train Loss: 0.6438 and lr: 0.0001\n",
      "train Loss: 0.6426 and lr: 0.0001\n",
      "train Loss: 0.6415 and lr: 0.0001\n",
      "train Loss: 0.6482 and lr: 0.0001\n",
      "train Loss: 0.6454 and lr: 0.0001\n",
      "Step 4/30\n",
      "----------\n",
      "train Loss: 0.3976 and lr: 0.0001\n",
      "train Loss: 0.4374 and lr: 0.0001\n",
      "train Loss: 0.4457 and lr: 0.0001\n",
      "train Loss: 0.4705 and lr: 0.0001\n",
      "train Loss: 0.5020 and lr: 0.0001\n",
      "train Loss: 0.6003 and lr: 0.0001\n",
      "train Loss: 0.5934 and lr: 0.0001\n",
      "train Loss: 0.5870 and lr: 0.0001\n",
      "train Loss: 0.5751 and lr: 0.0001\n",
      "train Loss: 0.5682 and lr: 0.0001\n",
      "train Loss: 0.6074 and lr: 0.0001\n",
      "train Loss: 0.5952 and lr: 0.0001\n",
      "train Loss: 0.5947 and lr: 0.0001\n",
      "train Loss: 0.5844 and lr: 0.0001\n",
      "train Loss: 0.5768 and lr: 0.0001\n",
      "train Loss: 0.6133 and lr: 0.0001\n",
      "train Loss: 0.6110 and lr: 0.0001\n",
      "train Loss: 0.6274 and lr: 0.0001\n",
      "train Loss: 0.6627 and lr: 0.0001\n",
      "train Loss: 0.6499 and lr: 0.0001\n",
      "train Loss: 0.6574 and lr: 0.0001\n",
      "train Loss: 0.6517 and lr: 0.0001\n",
      "train Loss: 0.6497 and lr: 0.0001\n",
      "train Loss: 0.6492 and lr: 0.0001\n",
      "train Loss: 0.6638 and lr: 0.0001\n",
      "train Loss: 0.6778 and lr: 0.0001\n",
      "train Loss: 0.6935 and lr: 0.0001\n",
      "train Loss: 0.6907 and lr: 0.0001\n",
      "train Loss: 0.6961 and lr: 0.0001\n",
      "train Loss: 0.6861 and lr: 0.0001\n",
      "train Loss: 0.6811 and lr: 0.0001\n",
      "train Loss: 0.6702 and lr: 0.0001\n",
      "train Loss: 0.6645 and lr: 0.0001\n",
      "train Loss: 0.6576 and lr: 0.0001\n",
      "train Loss: 0.6538 and lr: 0.0001\n",
      "train Loss: 0.6513 and lr: 0.0001\n",
      "train Loss: 0.6442 and lr: 0.0001\n",
      "train Loss: 0.6558 and lr: 0.0001\n",
      "train Loss: 0.6689 and lr: 0.0001\n",
      "train Loss: 0.6661 and lr: 0.0001\n",
      "train Loss: 0.6580 and lr: 0.0001\n",
      "train Loss: 0.6739 and lr: 0.0001\n",
      "train Loss: 0.6716 and lr: 0.0001\n",
      "train Loss: 0.6801 and lr: 0.0001\n",
      "train Loss: 0.6887 and lr: 0.0001\n",
      "train Loss: 0.6834 and lr: 0.0001\n",
      "train Loss: 0.6763 and lr: 0.0001\n",
      "train Loss: 0.6802 and lr: 0.0001\n",
      "train Loss: 0.6838 and lr: 0.0001\n",
      "train Loss: 0.6923 and lr: 0.0001\n",
      "train Loss: 0.6880 and lr: 0.0001\n",
      "train Loss: 0.6900 and lr: 0.0001\n",
      "train Loss: 0.6850 and lr: 0.0001\n",
      "train Loss: 0.6827 and lr: 0.0001\n",
      "train Loss: 0.6877 and lr: 0.0001\n",
      "Step 5/30\n",
      "----------\n",
      "train Loss: 0.5317 and lr: 0.0001\n",
      "train Loss: 0.5203 and lr: 0.0001\n",
      "train Loss: 0.5415 and lr: 0.0001\n",
      "train Loss: 0.5390 and lr: 0.0001\n",
      "train Loss: 0.5125 and lr: 0.0001\n",
      "train Loss: 0.5628 and lr: 0.0001\n",
      "train Loss: 0.6249 and lr: 0.0001\n",
      "train Loss: 0.6451 and lr: 0.0001\n",
      "train Loss: 0.6255 and lr: 0.0001\n",
      "train Loss: 0.6128 and lr: 0.0001\n",
      "train Loss: 0.5964 and lr: 0.0001\n",
      "train Loss: 0.6193 and lr: 0.0001\n",
      "train Loss: 0.6039 and lr: 0.0001\n",
      "train Loss: 0.6318 and lr: 0.0001\n",
      "train Loss: 0.6281 and lr: 0.0001\n",
      "train Loss: 0.6191 and lr: 0.0001\n",
      "train Loss: 0.6329 and lr: 0.0001\n",
      "train Loss: 0.6219 and lr: 0.0001\n",
      "train Loss: 0.6358 and lr: 0.0001\n",
      "train Loss: 0.6436 and lr: 0.0001\n",
      "train Loss: 0.6358 and lr: 0.0001\n",
      "train Loss: 0.6468 and lr: 0.0001\n",
      "train Loss: 0.6618 and lr: 0.0001\n",
      "train Loss: 0.6620 and lr: 0.0001\n",
      "train Loss: 0.6552 and lr: 0.0001\n",
      "train Loss: 0.6522 and lr: 0.0001\n",
      "train Loss: 0.6496 and lr: 0.0001\n",
      "train Loss: 0.6590 and lr: 0.0001\n",
      "train Loss: 0.6578 and lr: 0.0001\n",
      "train Loss: 0.6576 and lr: 0.0001\n",
      "train Loss: 0.6538 and lr: 0.0001\n",
      "train Loss: 0.6621 and lr: 0.0001\n",
      "train Loss: 0.6731 and lr: 0.0001\n",
      "train Loss: 0.6728 and lr: 0.0001\n",
      "train Loss: 0.6839 and lr: 0.0001\n",
      "train Loss: 0.6948 and lr: 0.0001\n",
      "train Loss: 0.6897 and lr: 0.0001\n",
      "train Loss: 0.6945 and lr: 0.0001\n",
      "train Loss: 0.6887 and lr: 0.0001\n",
      "train Loss: 0.6831 and lr: 0.0001\n",
      "train Loss: 0.6803 and lr: 0.0001\n",
      "train Loss: 0.6745 and lr: 0.0001\n",
      "train Loss: 0.6695 and lr: 0.0001\n",
      "train Loss: 0.6657 and lr: 0.0001\n",
      "train Loss: 0.6678 and lr: 0.0001\n",
      "train Loss: 0.6650 and lr: 0.0001\n",
      "train Loss: 0.6600 and lr: 0.0001\n",
      "train Loss: 0.6655 and lr: 0.0001\n",
      "train Loss: 0.6621 and lr: 0.0001\n",
      "train Loss: 0.6580 and lr: 0.0001\n",
      "train Loss: 0.6567 and lr: 0.0001\n",
      "train Loss: 0.6535 and lr: 0.0001\n",
      "train Loss: 0.6490 and lr: 0.0001\n",
      "train Loss: 0.6547 and lr: 0.0001\n",
      "train Loss: 0.6641 and lr: 0.0001\n",
      "Step 6/30\n",
      "----------\n",
      "train Loss: 0.5676 and lr: 0.0001\n",
      "train Loss: 0.7836 and lr: 0.0001\n",
      "train Loss: 0.6702 and lr: 0.0001\n",
      "train Loss: 0.7710 and lr: 0.0001\n",
      "train Loss: 0.7033 and lr: 0.0001\n",
      "train Loss: 0.6667 and lr: 0.0001\n",
      "train Loss: 0.6493 and lr: 0.0001\n",
      "train Loss: 0.6340 and lr: 0.0001\n",
      "train Loss: 0.6873 and lr: 0.0001\n",
      "train Loss: 0.6971 and lr: 0.0001\n",
      "train Loss: 0.7147 and lr: 0.0001\n",
      "train Loss: 0.7433 and lr: 0.0001\n",
      "train Loss: 0.7311 and lr: 0.0001\n",
      "train Loss: 0.7157 and lr: 0.0001\n",
      "train Loss: 0.7021 and lr: 0.0001\n",
      "train Loss: 0.6893 and lr: 0.0001\n",
      "train Loss: 0.6706 and lr: 0.0001\n",
      "train Loss: 0.6770 and lr: 0.0001\n",
      "train Loss: 0.6645 and lr: 0.0001\n",
      "train Loss: 0.6572 and lr: 0.0001\n",
      "train Loss: 0.6752 and lr: 0.0001\n",
      "train Loss: 0.6719 and lr: 0.0001\n",
      "train Loss: 0.6642 and lr: 0.0001\n",
      "train Loss: 0.6615 and lr: 0.0001\n",
      "train Loss: 0.6493 and lr: 0.0001\n",
      "train Loss: 0.6427 and lr: 0.0001\n",
      "train Loss: 0.6392 and lr: 0.0001\n",
      "train Loss: 0.6297 and lr: 0.0001\n",
      "train Loss: 0.6237 and lr: 0.0001\n",
      "train Loss: 0.6187 and lr: 0.0001\n",
      "train Loss: 0.6121 and lr: 0.0001\n",
      "train Loss: 0.6208 and lr: 0.0001\n",
      "train Loss: 0.6140 and lr: 0.0001\n",
      "train Loss: 0.6072 and lr: 0.0001\n",
      "train Loss: 0.6266 and lr: 0.0001\n",
      "train Loss: 0.6198 and lr: 0.0001\n",
      "train Loss: 0.6151 and lr: 0.0001\n",
      "train Loss: 0.6261 and lr: 0.0001\n",
      "train Loss: 0.6186 and lr: 0.0001\n",
      "train Loss: 0.6108 and lr: 0.0001\n",
      "train Loss: 0.6175 and lr: 0.0001\n",
      "train Loss: 0.6244 and lr: 0.0001\n",
      "train Loss: 0.6188 and lr: 0.0001\n",
      "train Loss: 0.6331 and lr: 0.0001\n",
      "train Loss: 0.6443 and lr: 0.0001\n",
      "train Loss: 0.6409 and lr: 0.0001\n",
      "train Loss: 0.6475 and lr: 0.0001\n",
      "train Loss: 0.6586 and lr: 0.0001\n",
      "train Loss: 0.6568 and lr: 0.0001\n",
      "train Loss: 0.6547 and lr: 0.0001\n",
      "train Loss: 0.6526 and lr: 0.0001\n",
      "train Loss: 0.6559 and lr: 0.0001\n",
      "train Loss: 0.6501 and lr: 0.0001\n",
      "train Loss: 0.6591 and lr: 0.0001\n",
      "train Loss: 0.6705 and lr: 0.0001\n",
      "Step 7/30\n",
      "----------\n",
      "train Loss: 1.2007 and lr: 0.0001\n",
      "train Loss: 0.8714 and lr: 0.0001\n",
      "train Loss: 0.9468 and lr: 0.0001\n",
      "train Loss: 0.8406 and lr: 0.0001\n",
      "train Loss: 0.7613 and lr: 0.0001\n",
      "train Loss: 0.7229 and lr: 0.0001\n",
      "train Loss: 0.6799 and lr: 0.0001\n",
      "train Loss: 0.7221 and lr: 0.0001\n",
      "train Loss: 0.7233 and lr: 0.0001\n",
      "train Loss: 0.7008 and lr: 0.0001\n",
      "train Loss: 0.6738 and lr: 0.0001\n",
      "train Loss: 0.6825 and lr: 0.0001\n",
      "train Loss: 0.6667 and lr: 0.0001\n",
      "train Loss: 0.6916 and lr: 0.0001\n",
      "train Loss: 0.7054 and lr: 0.0001\n",
      "train Loss: 0.6946 and lr: 0.0001\n",
      "train Loss: 0.6758 and lr: 0.0001\n",
      "train Loss: 0.6689 and lr: 0.0001\n",
      "train Loss: 0.6565 and lr: 0.0001\n",
      "train Loss: 0.6480 and lr: 0.0001\n",
      "train Loss: 0.6603 and lr: 0.0001\n",
      "train Loss: 0.6462 and lr: 0.0001\n",
      "train Loss: 0.6692 and lr: 0.0001\n",
      "train Loss: 0.6795 and lr: 0.0001\n",
      "train Loss: 0.6719 and lr: 0.0001\n",
      "train Loss: 0.6625 and lr: 0.0001\n",
      "train Loss: 0.6715 and lr: 0.0001\n",
      "train Loss: 0.6825 and lr: 0.0001\n",
      "train Loss: 0.6948 and lr: 0.0001\n",
      "train Loss: 0.7056 and lr: 0.0001\n",
      "train Loss: 0.7010 and lr: 0.0001\n",
      "train Loss: 0.6935 and lr: 0.0001\n",
      "train Loss: 0.6887 and lr: 0.0001\n",
      "train Loss: 0.6966 and lr: 0.0001\n",
      "train Loss: 0.6904 and lr: 0.0001\n",
      "train Loss: 0.6971 and lr: 0.0001\n",
      "train Loss: 0.7088 and lr: 0.0001\n",
      "train Loss: 0.7108 and lr: 0.0001\n",
      "train Loss: 0.7058 and lr: 0.0001\n",
      "train Loss: 0.7019 and lr: 0.0001\n",
      "train Loss: 0.6986 and lr: 0.0001\n",
      "train Loss: 0.6962 and lr: 0.0001\n",
      "train Loss: 0.6939 and lr: 0.0001\n",
      "train Loss: 0.6910 and lr: 0.0001\n",
      "train Loss: 0.6886 and lr: 0.0001\n",
      "train Loss: 0.6842 and lr: 0.0001\n",
      "train Loss: 0.6800 and lr: 0.0001\n",
      "train Loss: 0.6859 and lr: 0.0001\n",
      "train Loss: 0.6810 and lr: 0.0001\n",
      "train Loss: 0.6817 and lr: 0.0001\n",
      "train Loss: 0.6798 and lr: 0.0001\n",
      "train Loss: 0.6766 and lr: 0.0001\n",
      "train Loss: 0.6715 and lr: 0.0001\n",
      "train Loss: 0.6700 and lr: 0.0001\n",
      "train Loss: 0.6663 and lr: 0.0001\n",
      "Step 8/30\n",
      "----------\n",
      "train Loss: 1.0799 and lr: 0.0001\n",
      "train Loss: 0.7559 and lr: 0.0001\n",
      "train Loss: 0.7840 and lr: 0.0001\n",
      "train Loss: 0.7035 and lr: 0.0001\n",
      "train Loss: 0.7574 and lr: 0.0001\n",
      "train Loss: 0.7168 and lr: 0.0001\n",
      "train Loss: 0.7168 and lr: 0.0001\n",
      "train Loss: 0.7234 and lr: 0.0001\n",
      "train Loss: 0.6955 and lr: 0.0001\n",
      "train Loss: 0.7159 and lr: 0.0001\n",
      "train Loss: 0.7075 and lr: 0.0001\n",
      "train Loss: 0.7041 and lr: 0.0001\n",
      "train Loss: 0.6775 and lr: 0.0001\n",
      "train Loss: 0.6628 and lr: 0.0001\n",
      "train Loss: 0.6494 and lr: 0.0001\n",
      "train Loss: 0.6858 and lr: 0.0001\n",
      "train Loss: 0.6979 and lr: 0.0001\n",
      "train Loss: 0.6898 and lr: 0.0001\n",
      "train Loss: 0.6792 and lr: 0.0001\n",
      "train Loss: 0.6663 and lr: 0.0001\n",
      "train Loss: 0.6564 and lr: 0.0001\n",
      "train Loss: 0.6468 and lr: 0.0001\n",
      "train Loss: 0.6371 and lr: 0.0001\n",
      "train Loss: 0.6395 and lr: 0.0001\n",
      "train Loss: 0.6346 and lr: 0.0001\n",
      "train Loss: 0.6489 and lr: 0.0001\n",
      "train Loss: 0.6435 and lr: 0.0001\n",
      "train Loss: 0.6399 and lr: 0.0001\n",
      "train Loss: 0.6348 and lr: 0.0001\n",
      "train Loss: 0.6341 and lr: 0.0001\n",
      "train Loss: 0.6580 and lr: 0.0001\n",
      "train Loss: 0.6514 and lr: 0.0001\n",
      "train Loss: 0.6599 and lr: 0.0001\n",
      "train Loss: 0.6536 and lr: 0.0001\n",
      "train Loss: 0.6500 and lr: 0.0001\n",
      "train Loss: 0.6564 and lr: 0.0001\n",
      "train Loss: 0.6511 and lr: 0.0001\n",
      "train Loss: 0.6591 and lr: 0.0001\n",
      "train Loss: 0.6712 and lr: 0.0001\n",
      "train Loss: 0.6705 and lr: 0.0001\n",
      "train Loss: 0.6658 and lr: 0.0001\n",
      "train Loss: 0.6633 and lr: 0.0001\n",
      "train Loss: 0.6715 and lr: 0.0001\n",
      "train Loss: 0.6837 and lr: 0.0001\n",
      "train Loss: 0.6782 and lr: 0.0001\n",
      "train Loss: 0.6864 and lr: 0.0001\n",
      "train Loss: 0.6989 and lr: 0.0001\n",
      "train Loss: 0.7006 and lr: 0.0001\n",
      "train Loss: 0.6981 and lr: 0.0001\n",
      "train Loss: 0.6958 and lr: 0.0001\n",
      "train Loss: 0.7025 and lr: 0.0001\n",
      "train Loss: 0.6994 and lr: 0.0001\n",
      "train Loss: 0.6946 and lr: 0.0001\n",
      "train Loss: 0.6890 and lr: 0.0001\n",
      "train Loss: 0.6920 and lr: 0.0001\n",
      "Step 9/30\n",
      "----------\n",
      "train Loss: 0.5378 and lr: 0.0001\n",
      "train Loss: 0.7484 and lr: 0.0001\n",
      "train Loss: 0.8751 and lr: 0.0001\n",
      "train Loss: 0.7736 and lr: 0.0001\n",
      "train Loss: 0.7286 and lr: 0.0001\n",
      "train Loss: 0.7714 and lr: 0.0001\n",
      "train Loss: 0.8185 and lr: 0.0001\n",
      "train Loss: 0.7734 and lr: 0.0001\n",
      "train Loss: 0.7784 and lr: 0.0001\n",
      "train Loss: 0.7442 and lr: 0.0001\n",
      "train Loss: 0.7327 and lr: 0.0001\n",
      "train Loss: 0.7389 and lr: 0.0001\n",
      "train Loss: 0.7629 and lr: 0.0001\n",
      "train Loss: 0.7842 and lr: 0.0001\n",
      "train Loss: 0.7977 and lr: 0.0001\n",
      "train Loss: 0.7814 and lr: 0.0001\n",
      "train Loss: 0.7830 and lr: 0.0001\n",
      "train Loss: 0.7930 and lr: 0.0001\n",
      "train Loss: 0.7781 and lr: 0.0001\n",
      "train Loss: 0.7693 and lr: 0.0001\n",
      "train Loss: 0.7644 and lr: 0.0001\n",
      "train Loss: 0.7546 and lr: 0.0001\n",
      "train Loss: 0.7595 and lr: 0.0001\n",
      "train Loss: 0.7529 and lr: 0.0001\n",
      "train Loss: 0.7564 and lr: 0.0001\n",
      "train Loss: 0.7478 and lr: 0.0001\n",
      "train Loss: 0.7386 and lr: 0.0001\n",
      "train Loss: 0.7343 and lr: 0.0001\n",
      "train Loss: 0.7315 and lr: 0.0001\n",
      "train Loss: 0.7266 and lr: 0.0001\n",
      "train Loss: 0.7202 and lr: 0.0001\n",
      "train Loss: 0.7161 and lr: 0.0001\n",
      "train Loss: 0.7091 and lr: 0.0001\n",
      "train Loss: 0.7029 and lr: 0.0001\n",
      "train Loss: 0.6985 and lr: 0.0001\n",
      "train Loss: 0.6963 and lr: 0.0001\n",
      "train Loss: 0.6924 and lr: 0.0001\n",
      "train Loss: 0.6886 and lr: 0.0001\n",
      "train Loss: 0.6918 and lr: 0.0001\n",
      "train Loss: 0.6862 and lr: 0.0001\n",
      "train Loss: 0.6935 and lr: 0.0001\n",
      "train Loss: 0.6883 and lr: 0.0001\n",
      "train Loss: 0.6832 and lr: 0.0001\n",
      "train Loss: 0.6799 and lr: 0.0001\n",
      "train Loss: 0.6742 and lr: 0.0001\n",
      "train Loss: 0.6721 and lr: 0.0001\n",
      "train Loss: 0.6821 and lr: 0.0001\n",
      "train Loss: 0.6800 and lr: 0.0001\n",
      "train Loss: 0.6853 and lr: 0.0001\n",
      "train Loss: 0.6889 and lr: 0.0001\n",
      "train Loss: 0.6862 and lr: 0.0001\n",
      "train Loss: 0.6820 and lr: 0.0001\n",
      "train Loss: 0.6787 and lr: 0.0001\n",
      "train Loss: 0.6827 and lr: 0.0001\n",
      "train Loss: 0.6860 and lr: 0.0001\n",
      "Step 10/30\n",
      "----------\n",
      "train Loss: 0.4497 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.4381 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.4811 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.4898 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.4674 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5005 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5587 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5968 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5946 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5916 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5876 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5742 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5698 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5700 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5687 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5553 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5532 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5772 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5892 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5884 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6012 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6013 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5922 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5882 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5808 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5942 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6022 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6195 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6275 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6277 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6238 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6320 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6362 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6420 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6355 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6408 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6354 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6471 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6433 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6500 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6482 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6431 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6480 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6447 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6417 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6381 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6372 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6352 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6313 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6344 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6323 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6421 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6400 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6467 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6536 and lr: 1.0000000000000002e-06\n",
      "Step 11/30\n",
      "----------\n",
      "train Loss: 0.5052 and lr: 1e-05\n",
      "train Loss: 0.7528 and lr: 1e-05\n",
      "train Loss: 0.6949 and lr: 1e-05\n",
      "train Loss: 0.6405 and lr: 1e-05\n",
      "train Loss: 0.6731 and lr: 1e-05\n",
      "train Loss: 0.7233 and lr: 1e-05\n",
      "train Loss: 0.6729 and lr: 1e-05\n",
      "train Loss: 0.7214 and lr: 1e-05\n",
      "train Loss: 0.7012 and lr: 1e-05\n",
      "train Loss: 0.7216 and lr: 1e-05\n",
      "train Loss: 0.7322 and lr: 1e-05\n",
      "train Loss: 0.7560 and lr: 1e-05\n",
      "train Loss: 0.7285 and lr: 1e-05\n",
      "train Loss: 0.7344 and lr: 1e-05\n",
      "train Loss: 0.7141 and lr: 1e-05\n",
      "train Loss: 0.7112 and lr: 1e-05\n",
      "train Loss: 0.6978 and lr: 1e-05\n",
      "train Loss: 0.6833 and lr: 1e-05\n",
      "train Loss: 0.6976 and lr: 1e-05\n",
      "train Loss: 0.7038 and lr: 1e-05\n",
      "train Loss: 0.6915 and lr: 1e-05\n",
      "train Loss: 0.6868 and lr: 1e-05\n",
      "train Loss: 0.6747 and lr: 1e-05\n",
      "train Loss: 0.6613 and lr: 1e-05\n",
      "train Loss: 0.6736 and lr: 1e-05\n",
      "train Loss: 0.6656 and lr: 1e-05\n",
      "train Loss: 0.6652 and lr: 1e-05\n",
      "train Loss: 0.6607 and lr: 1e-05\n",
      "train Loss: 0.6680 and lr: 1e-05\n",
      "train Loss: 0.6583 and lr: 1e-05\n",
      "train Loss: 0.6645 and lr: 1e-05\n",
      "train Loss: 0.6565 and lr: 1e-05\n",
      "train Loss: 0.6524 and lr: 1e-05\n",
      "train Loss: 0.6492 and lr: 1e-05\n",
      "train Loss: 0.6445 and lr: 1e-05\n",
      "train Loss: 0.6516 and lr: 1e-05\n",
      "train Loss: 0.6469 and lr: 1e-05\n",
      "train Loss: 0.6480 and lr: 1e-05\n",
      "train Loss: 0.6494 and lr: 1e-05\n",
      "train Loss: 0.6450 and lr: 1e-05\n",
      "train Loss: 0.6405 and lr: 1e-05\n",
      "train Loss: 0.6398 and lr: 1e-05\n",
      "train Loss: 0.6359 and lr: 1e-05\n",
      "train Loss: 0.6361 and lr: 1e-05\n",
      "train Loss: 0.6429 and lr: 1e-05\n",
      "train Loss: 0.6493 and lr: 1e-05\n",
      "train Loss: 0.6453 and lr: 1e-05\n",
      "train Loss: 0.6515 and lr: 1e-05\n",
      "train Loss: 0.6506 and lr: 1e-05\n",
      "train Loss: 0.6566 and lr: 1e-05\n",
      "train Loss: 0.6547 and lr: 1e-05\n",
      "train Loss: 0.6548 and lr: 1e-05\n",
      "train Loss: 0.6628 and lr: 1e-05\n",
      "train Loss: 0.6595 and lr: 1e-05\n",
      "train Loss: 0.6573 and lr: 1e-05\n",
      "Step 12/30\n",
      "----------\n",
      "train Loss: 1.0540 and lr: 1e-05\n",
      "train Loss: 0.9713 and lr: 1e-05\n",
      "train Loss: 0.9672 and lr: 1e-05\n",
      "train Loss: 0.9947 and lr: 1e-05\n",
      "train Loss: 0.9836 and lr: 1e-05\n",
      "train Loss: 0.9823 and lr: 1e-05\n",
      "train Loss: 0.9301 and lr: 1e-05\n",
      "train Loss: 0.9451 and lr: 1e-05\n",
      "train Loss: 0.9038 and lr: 1e-05\n",
      "train Loss: 0.9187 and lr: 1e-05\n",
      "train Loss: 0.9008 and lr: 1e-05\n",
      "train Loss: 0.8751 and lr: 1e-05\n",
      "train Loss: 0.8489 and lr: 1e-05\n",
      "train Loss: 0.8243 and lr: 1e-05\n",
      "train Loss: 0.8393 and lr: 1e-05\n",
      "train Loss: 0.8442 and lr: 1e-05\n",
      "train Loss: 0.8187 and lr: 1e-05\n",
      "train Loss: 0.8073 and lr: 1e-05\n",
      "train Loss: 0.7896 and lr: 1e-05\n",
      "train Loss: 0.7748 and lr: 1e-05\n",
      "train Loss: 0.7633 and lr: 1e-05\n",
      "train Loss: 0.7544 and lr: 1e-05\n",
      "train Loss: 0.7621 and lr: 1e-05\n",
      "train Loss: 0.7530 and lr: 1e-05\n",
      "train Loss: 0.7472 and lr: 1e-05\n",
      "train Loss: 0.7548 and lr: 1e-05\n",
      "train Loss: 0.7606 and lr: 1e-05\n",
      "train Loss: 0.7660 and lr: 1e-05\n",
      "train Loss: 0.7557 and lr: 1e-05\n",
      "train Loss: 0.7469 and lr: 1e-05\n",
      "train Loss: 0.7380 and lr: 1e-05\n",
      "train Loss: 0.7285 and lr: 1e-05\n",
      "train Loss: 0.7196 and lr: 1e-05\n",
      "train Loss: 0.7095 and lr: 1e-05\n",
      "train Loss: 0.7052 and lr: 1e-05\n",
      "train Loss: 0.7011 and lr: 1e-05\n",
      "train Loss: 0.6966 and lr: 1e-05\n",
      "train Loss: 0.7024 and lr: 1e-05\n",
      "train Loss: 0.6975 and lr: 1e-05\n",
      "train Loss: 0.6930 and lr: 1e-05\n",
      "train Loss: 0.6896 and lr: 1e-05\n",
      "train Loss: 0.6850 and lr: 1e-05\n",
      "train Loss: 0.6829 and lr: 1e-05\n",
      "train Loss: 0.6808 and lr: 1e-05\n",
      "train Loss: 0.6770 and lr: 1e-05\n",
      "train Loss: 0.6722 and lr: 1e-05\n",
      "train Loss: 0.6774 and lr: 1e-05\n",
      "train Loss: 0.6725 and lr: 1e-05\n",
      "train Loss: 0.6813 and lr: 1e-05\n",
      "train Loss: 0.6799 and lr: 1e-05\n",
      "train Loss: 0.6768 and lr: 1e-05\n",
      "train Loss: 0.6725 and lr: 1e-05\n",
      "train Loss: 0.6781 and lr: 1e-05\n",
      "train Loss: 0.6814 and lr: 1e-05\n",
      "train Loss: 0.6807 and lr: 1e-05\n",
      "Step 13/30\n",
      "----------\n",
      "train Loss: 0.8420 and lr: 1e-05\n",
      "train Loss: 0.6341 and lr: 1e-05\n",
      "train Loss: 0.5600 and lr: 1e-05\n",
      "train Loss: 0.7022 and lr: 1e-05\n",
      "train Loss: 0.6635 and lr: 1e-05\n",
      "train Loss: 0.6202 and lr: 1e-05\n",
      "train Loss: 0.5929 and lr: 1e-05\n",
      "train Loss: 0.5893 and lr: 1e-05\n",
      "train Loss: 0.5724 and lr: 1e-05\n",
      "train Loss: 0.5683 and lr: 1e-05\n",
      "train Loss: 0.5882 and lr: 1e-05\n",
      "train Loss: 0.5762 and lr: 1e-05\n",
      "train Loss: 0.5929 and lr: 1e-05\n",
      "train Loss: 0.6188 and lr: 1e-05\n",
      "train Loss: 0.6138 and lr: 1e-05\n",
      "train Loss: 0.6119 and lr: 1e-05\n",
      "train Loss: 0.6073 and lr: 1e-05\n",
      "train Loss: 0.6343 and lr: 1e-05\n",
      "train Loss: 0.6282 and lr: 1e-05\n",
      "train Loss: 0.6205 and lr: 1e-05\n",
      "train Loss: 0.6425 and lr: 1e-05\n",
      "train Loss: 0.6331 and lr: 1e-05\n",
      "train Loss: 0.6287 and lr: 1e-05\n",
      "train Loss: 0.6208 and lr: 1e-05\n",
      "train Loss: 0.6304 and lr: 1e-05\n",
      "train Loss: 0.6339 and lr: 1e-05\n",
      "train Loss: 0.6282 and lr: 1e-05\n",
      "train Loss: 0.6433 and lr: 1e-05\n",
      "train Loss: 0.6482 and lr: 1e-05\n",
      "train Loss: 0.6415 and lr: 1e-05\n",
      "train Loss: 0.6402 and lr: 1e-05\n",
      "train Loss: 0.6489 and lr: 1e-05\n",
      "train Loss: 0.6616 and lr: 1e-05\n",
      "train Loss: 0.6661 and lr: 1e-05\n",
      "train Loss: 0.6696 and lr: 1e-05\n",
      "train Loss: 0.6676 and lr: 1e-05\n",
      "train Loss: 0.6651 and lr: 1e-05\n",
      "train Loss: 0.6598 and lr: 1e-05\n",
      "train Loss: 0.6528 and lr: 1e-05\n",
      "train Loss: 0.6510 and lr: 1e-05\n",
      "train Loss: 0.6488 and lr: 1e-05\n",
      "train Loss: 0.6588 and lr: 1e-05\n",
      "train Loss: 0.6532 and lr: 1e-05\n",
      "train Loss: 0.6595 and lr: 1e-05\n",
      "train Loss: 0.6570 and lr: 1e-05\n",
      "train Loss: 0.6622 and lr: 1e-05\n",
      "train Loss: 0.6586 and lr: 1e-05\n",
      "train Loss: 0.6662 and lr: 1e-05\n",
      "train Loss: 0.6659 and lr: 1e-05\n",
      "train Loss: 0.6629 and lr: 1e-05\n",
      "train Loss: 0.6581 and lr: 1e-05\n",
      "train Loss: 0.6534 and lr: 1e-05\n",
      "train Loss: 0.6505 and lr: 1e-05\n",
      "train Loss: 0.6504 and lr: 1e-05\n",
      "train Loss: 0.6527 and lr: 1e-05\n",
      "Step 14/30\n",
      "----------\n",
      "train Loss: 0.9318 and lr: 1e-05\n",
      "train Loss: 0.7475 and lr: 1e-05\n",
      "train Loss: 0.8268 and lr: 1e-05\n",
      "train Loss: 0.7525 and lr: 1e-05\n",
      "train Loss: 0.7122 and lr: 1e-05\n",
      "train Loss: 0.7260 and lr: 1e-05\n",
      "train Loss: 0.6950 and lr: 1e-05\n",
      "train Loss: 0.7192 and lr: 1e-05\n",
      "train Loss: 0.7495 and lr: 1e-05\n",
      "train Loss: 0.7182 and lr: 1e-05\n",
      "train Loss: 0.7009 and lr: 1e-05\n",
      "train Loss: 0.6859 and lr: 1e-05\n",
      "train Loss: 0.6795 and lr: 1e-05\n",
      "train Loss: 0.6641 and lr: 1e-05\n",
      "train Loss: 0.6726 and lr: 1e-05\n",
      "train Loss: 0.6680 and lr: 1e-05\n",
      "train Loss: 0.6620 and lr: 1e-05\n",
      "train Loss: 0.6615 and lr: 1e-05\n",
      "train Loss: 0.6520 and lr: 1e-05\n",
      "train Loss: 0.6530 and lr: 1e-05\n",
      "train Loss: 0.6601 and lr: 1e-05\n",
      "train Loss: 0.6724 and lr: 1e-05\n",
      "train Loss: 0.6927 and lr: 1e-05\n",
      "train Loss: 0.6836 and lr: 1e-05\n",
      "train Loss: 0.6771 and lr: 1e-05\n",
      "train Loss: 0.6712 and lr: 1e-05\n",
      "train Loss: 0.6788 and lr: 1e-05\n",
      "train Loss: 0.6701 and lr: 1e-05\n",
      "train Loss: 0.6770 and lr: 1e-05\n",
      "train Loss: 0.6687 and lr: 1e-05\n",
      "train Loss: 0.6811 and lr: 1e-05\n",
      "train Loss: 0.6789 and lr: 1e-05\n",
      "train Loss: 0.6717 and lr: 1e-05\n",
      "train Loss: 0.6662 and lr: 1e-05\n",
      "train Loss: 0.6694 and lr: 1e-05\n",
      "train Loss: 0.6644 and lr: 1e-05\n",
      "train Loss: 0.6613 and lr: 1e-05\n",
      "train Loss: 0.6553 and lr: 1e-05\n",
      "train Loss: 0.6667 and lr: 1e-05\n",
      "train Loss: 0.6726 and lr: 1e-05\n",
      "train Loss: 0.6765 and lr: 1e-05\n",
      "train Loss: 0.6795 and lr: 1e-05\n",
      "train Loss: 0.6745 and lr: 1e-05\n",
      "train Loss: 0.6693 and lr: 1e-05\n",
      "train Loss: 0.6631 and lr: 1e-05\n",
      "train Loss: 0.6588 and lr: 1e-05\n",
      "train Loss: 0.6668 and lr: 1e-05\n",
      "train Loss: 0.6622 and lr: 1e-05\n",
      "train Loss: 0.6664 and lr: 1e-05\n",
      "train Loss: 0.6644 and lr: 1e-05\n",
      "train Loss: 0.6589 and lr: 1e-05\n",
      "train Loss: 0.6663 and lr: 1e-05\n",
      "train Loss: 0.6636 and lr: 1e-05\n",
      "train Loss: 0.6590 and lr: 1e-05\n",
      "train Loss: 0.6558 and lr: 1e-05\n",
      "Step 15/30\n",
      "----------\n",
      "train Loss: 0.5100 and lr: 1e-05\n",
      "train Loss: 0.5851 and lr: 1e-05\n",
      "train Loss: 0.6465 and lr: 1e-05\n",
      "train Loss: 0.6313 and lr: 1e-05\n",
      "train Loss: 0.6631 and lr: 1e-05\n",
      "train Loss: 0.6386 and lr: 1e-05\n",
      "train Loss: 0.6419 and lr: 1e-05\n",
      "train Loss: 0.6113 and lr: 1e-05\n",
      "train Loss: 0.6085 and lr: 1e-05\n",
      "train Loss: 0.6006 and lr: 1e-05\n",
      "train Loss: 0.5862 and lr: 1e-05\n",
      "train Loss: 0.6134 and lr: 1e-05\n",
      "train Loss: 0.6065 and lr: 1e-05\n",
      "train Loss: 0.6370 and lr: 1e-05\n",
      "train Loss: 0.6310 and lr: 1e-05\n",
      "train Loss: 0.6481 and lr: 1e-05\n",
      "train Loss: 0.6600 and lr: 1e-05\n",
      "train Loss: 0.6823 and lr: 1e-05\n",
      "train Loss: 0.6751 and lr: 1e-05\n",
      "train Loss: 0.6651 and lr: 1e-05\n",
      "train Loss: 0.6551 and lr: 1e-05\n",
      "train Loss: 0.6540 and lr: 1e-05\n",
      "train Loss: 0.6412 and lr: 1e-05\n",
      "train Loss: 0.6354 and lr: 1e-05\n",
      "train Loss: 0.6328 and lr: 1e-05\n",
      "train Loss: 0.6266 and lr: 1e-05\n",
      "train Loss: 0.6369 and lr: 1e-05\n",
      "train Loss: 0.6278 and lr: 1e-05\n",
      "train Loss: 0.6412 and lr: 1e-05\n",
      "train Loss: 0.6557 and lr: 1e-05\n",
      "train Loss: 0.6538 and lr: 1e-05\n",
      "train Loss: 0.6665 and lr: 1e-05\n",
      "train Loss: 0.6606 and lr: 1e-05\n",
      "train Loss: 0.6537 and lr: 1e-05\n",
      "train Loss: 0.6477 and lr: 1e-05\n",
      "train Loss: 0.6563 and lr: 1e-05\n",
      "train Loss: 0.6569 and lr: 1e-05\n",
      "train Loss: 0.6508 and lr: 1e-05\n",
      "train Loss: 0.6593 and lr: 1e-05\n",
      "train Loss: 0.6664 and lr: 1e-05\n",
      "train Loss: 0.6681 and lr: 1e-05\n",
      "train Loss: 0.6620 and lr: 1e-05\n",
      "train Loss: 0.6698 and lr: 1e-05\n",
      "train Loss: 0.6643 and lr: 1e-05\n",
      "train Loss: 0.6616 and lr: 1e-05\n",
      "train Loss: 0.6578 and lr: 1e-05\n",
      "train Loss: 0.6532 and lr: 1e-05\n",
      "train Loss: 0.6501 and lr: 1e-05\n",
      "train Loss: 0.6558 and lr: 1e-05\n",
      "train Loss: 0.6521 and lr: 1e-05\n",
      "train Loss: 0.6481 and lr: 1e-05\n",
      "train Loss: 0.6447 and lr: 1e-05\n",
      "train Loss: 0.6493 and lr: 1e-05\n",
      "train Loss: 0.6524 and lr: 1e-05\n",
      "train Loss: 0.6573 and lr: 1e-05\n",
      "Step 16/30\n",
      "----------\n",
      "train Loss: 0.8541 and lr: 1e-05\n",
      "train Loss: 0.6835 and lr: 1e-05\n",
      "train Loss: 0.6502 and lr: 1e-05\n",
      "train Loss: 0.6126 and lr: 1e-05\n",
      "train Loss: 0.6127 and lr: 1e-05\n",
      "train Loss: 0.5962 and lr: 1e-05\n",
      "train Loss: 0.5861 and lr: 1e-05\n",
      "train Loss: 0.6327 and lr: 1e-05\n",
      "train Loss: 0.6359 and lr: 1e-05\n",
      "train Loss: 0.6199 and lr: 1e-05\n",
      "train Loss: 0.6205 and lr: 1e-05\n",
      "train Loss: 0.6423 and lr: 1e-05\n",
      "train Loss: 0.6593 and lr: 1e-05\n",
      "train Loss: 0.6712 and lr: 1e-05\n",
      "train Loss: 0.6553 and lr: 1e-05\n",
      "train Loss: 0.6481 and lr: 1e-05\n",
      "train Loss: 0.6494 and lr: 1e-05\n",
      "train Loss: 0.6453 and lr: 1e-05\n",
      "train Loss: 0.6309 and lr: 1e-05\n",
      "train Loss: 0.6189 and lr: 1e-05\n",
      "train Loss: 0.6370 and lr: 1e-05\n",
      "train Loss: 0.6272 and lr: 1e-05\n",
      "train Loss: 0.6332 and lr: 1e-05\n",
      "train Loss: 0.6275 and lr: 1e-05\n",
      "train Loss: 0.6364 and lr: 1e-05\n",
      "train Loss: 0.6333 and lr: 1e-05\n",
      "train Loss: 0.6488 and lr: 1e-05\n",
      "train Loss: 0.6474 and lr: 1e-05\n",
      "train Loss: 0.6433 and lr: 1e-05\n",
      "train Loss: 0.6395 and lr: 1e-05\n",
      "train Loss: 0.6471 and lr: 1e-05\n",
      "train Loss: 0.6540 and lr: 1e-05\n",
      "train Loss: 0.6516 and lr: 1e-05\n",
      "train Loss: 0.6633 and lr: 1e-05\n",
      "train Loss: 0.6564 and lr: 1e-05\n",
      "train Loss: 0.6527 and lr: 1e-05\n",
      "train Loss: 0.6657 and lr: 1e-05\n",
      "train Loss: 0.6598 and lr: 1e-05\n",
      "train Loss: 0.6590 and lr: 1e-05\n",
      "train Loss: 0.6683 and lr: 1e-05\n",
      "train Loss: 0.6786 and lr: 1e-05\n",
      "train Loss: 0.6709 and lr: 1e-05\n",
      "train Loss: 0.6674 and lr: 1e-05\n",
      "train Loss: 0.6637 and lr: 1e-05\n",
      "train Loss: 0.6718 and lr: 1e-05\n",
      "train Loss: 0.6683 and lr: 1e-05\n",
      "train Loss: 0.6648 and lr: 1e-05\n",
      "train Loss: 0.6728 and lr: 1e-05\n",
      "train Loss: 0.6697 and lr: 1e-05\n",
      "train Loss: 0.6752 and lr: 1e-05\n",
      "train Loss: 0.6688 and lr: 1e-05\n",
      "train Loss: 0.6753 and lr: 1e-05\n",
      "train Loss: 0.6850 and lr: 1e-05\n",
      "train Loss: 0.6836 and lr: 1e-05\n",
      "train Loss: 0.6802 and lr: 1e-05\n",
      "Step 17/30\n",
      "----------\n",
      "train Loss: 0.4220 and lr: 1e-05\n",
      "train Loss: 0.4271 and lr: 1e-05\n",
      "train Loss: 0.4801 and lr: 1e-05\n",
      "train Loss: 0.5665 and lr: 1e-05\n",
      "train Loss: 0.5374 and lr: 1e-05\n",
      "train Loss: 0.5314 and lr: 1e-05\n",
      "train Loss: 0.5516 and lr: 1e-05\n",
      "train Loss: 0.5341 and lr: 1e-05\n",
      "train Loss: 0.5788 and lr: 1e-05\n",
      "train Loss: 0.6139 and lr: 1e-05\n",
      "train Loss: 0.6344 and lr: 1e-05\n",
      "train Loss: 0.6312 and lr: 1e-05\n",
      "train Loss: 0.6457 and lr: 1e-05\n",
      "train Loss: 0.6379 and lr: 1e-05\n",
      "train Loss: 0.6196 and lr: 1e-05\n",
      "train Loss: 0.6094 and lr: 1e-05\n",
      "train Loss: 0.6029 and lr: 1e-05\n",
      "train Loss: 0.6133 and lr: 1e-05\n",
      "train Loss: 0.6045 and lr: 1e-05\n",
      "train Loss: 0.5966 and lr: 1e-05\n",
      "train Loss: 0.5909 and lr: 1e-05\n",
      "train Loss: 0.6068 and lr: 1e-05\n",
      "train Loss: 0.6075 and lr: 1e-05\n",
      "train Loss: 0.6013 and lr: 1e-05\n",
      "train Loss: 0.5954 and lr: 1e-05\n",
      "train Loss: 0.6118 and lr: 1e-05\n",
      "train Loss: 0.6294 and lr: 1e-05\n",
      "train Loss: 0.6209 and lr: 1e-05\n",
      "train Loss: 0.6165 and lr: 1e-05\n",
      "train Loss: 0.6135 and lr: 1e-05\n",
      "train Loss: 0.6060 and lr: 1e-05\n",
      "train Loss: 0.5999 and lr: 1e-05\n",
      "train Loss: 0.6049 and lr: 1e-05\n",
      "train Loss: 0.6006 and lr: 1e-05\n",
      "train Loss: 0.6142 and lr: 1e-05\n",
      "train Loss: 0.6190 and lr: 1e-05\n",
      "train Loss: 0.6169 and lr: 1e-05\n",
      "train Loss: 0.6311 and lr: 1e-05\n",
      "train Loss: 0.6385 and lr: 1e-05\n",
      "train Loss: 0.6484 and lr: 1e-05\n",
      "train Loss: 0.6552 and lr: 1e-05\n",
      "train Loss: 0.6516 and lr: 1e-05\n",
      "train Loss: 0.6556 and lr: 1e-05\n",
      "train Loss: 0.6513 and lr: 1e-05\n",
      "train Loss: 0.6509 and lr: 1e-05\n",
      "train Loss: 0.6567 and lr: 1e-05\n",
      "train Loss: 0.6511 and lr: 1e-05\n",
      "train Loss: 0.6483 and lr: 1e-05\n",
      "train Loss: 0.6469 and lr: 1e-05\n",
      "train Loss: 0.6432 and lr: 1e-05\n",
      "train Loss: 0.6488 and lr: 1e-05\n",
      "train Loss: 0.6501 and lr: 1e-05\n",
      "train Loss: 0.6453 and lr: 1e-05\n",
      "train Loss: 0.6417 and lr: 1e-05\n",
      "train Loss: 0.6389 and lr: 1e-05\n",
      "Step 18/30\n",
      "----------\n",
      "train Loss: 0.5848 and lr: 1e-05\n",
      "train Loss: 0.8366 and lr: 1e-05\n",
      "train Loss: 0.7458 and lr: 1e-05\n",
      "train Loss: 0.7031 and lr: 1e-05\n",
      "train Loss: 0.7810 and lr: 1e-05\n",
      "train Loss: 0.7545 and lr: 1e-05\n",
      "train Loss: 0.8072 and lr: 1e-05\n",
      "train Loss: 0.7831 and lr: 1e-05\n",
      "train Loss: 0.7920 and lr: 1e-05\n",
      "train Loss: 0.7648 and lr: 1e-05\n",
      "train Loss: 0.7424 and lr: 1e-05\n",
      "train Loss: 0.7164 and lr: 1e-05\n",
      "train Loss: 0.6946 and lr: 1e-05\n",
      "train Loss: 0.6842 and lr: 1e-05\n",
      "train Loss: 0.6723 and lr: 1e-05\n",
      "train Loss: 0.6652 and lr: 1e-05\n",
      "train Loss: 0.6552 and lr: 1e-05\n",
      "train Loss: 0.6809 and lr: 1e-05\n",
      "train Loss: 0.6744 and lr: 1e-05\n",
      "train Loss: 0.6912 and lr: 1e-05\n",
      "train Loss: 0.7013 and lr: 1e-05\n",
      "train Loss: 0.6880 and lr: 1e-05\n",
      "train Loss: 0.6724 and lr: 1e-05\n",
      "train Loss: 0.6660 and lr: 1e-05\n",
      "train Loss: 0.6591 and lr: 1e-05\n",
      "train Loss: 0.6496 and lr: 1e-05\n",
      "train Loss: 0.6626 and lr: 1e-05\n",
      "train Loss: 0.6805 and lr: 1e-05\n",
      "train Loss: 0.6749 and lr: 1e-05\n",
      "train Loss: 0.6688 and lr: 1e-05\n",
      "train Loss: 0.6677 and lr: 1e-05\n",
      "train Loss: 0.6597 and lr: 1e-05\n",
      "train Loss: 0.6662 and lr: 1e-05\n",
      "train Loss: 0.6741 and lr: 1e-05\n",
      "train Loss: 0.6832 and lr: 1e-05\n",
      "train Loss: 0.6750 and lr: 1e-05\n",
      "train Loss: 0.6710 and lr: 1e-05\n",
      "train Loss: 0.6845 and lr: 1e-05\n",
      "train Loss: 0.6876 and lr: 1e-05\n",
      "train Loss: 0.6914 and lr: 1e-05\n",
      "train Loss: 0.6850 and lr: 1e-05\n",
      "train Loss: 0.6787 and lr: 1e-05\n",
      "train Loss: 0.6740 and lr: 1e-05\n",
      "train Loss: 0.6689 and lr: 1e-05\n",
      "train Loss: 0.6682 and lr: 1e-05\n",
      "train Loss: 0.6723 and lr: 1e-05\n",
      "train Loss: 0.6760 and lr: 1e-05\n",
      "train Loss: 0.6783 and lr: 1e-05\n",
      "train Loss: 0.6773 and lr: 1e-05\n",
      "train Loss: 0.6750 and lr: 1e-05\n",
      "train Loss: 0.6830 and lr: 1e-05\n",
      "train Loss: 0.6796 and lr: 1e-05\n",
      "train Loss: 0.6860 and lr: 1e-05\n",
      "train Loss: 0.6812 and lr: 1e-05\n",
      "train Loss: 0.6779 and lr: 1e-05\n",
      "Step 19/30\n",
      "----------\n",
      "train Loss: 0.4992 and lr: 1e-05\n",
      "train Loss: 0.4539 and lr: 1e-05\n",
      "train Loss: 0.6481 and lr: 1e-05\n",
      "train Loss: 0.6013 and lr: 1e-05\n",
      "train Loss: 0.5874 and lr: 1e-05\n",
      "train Loss: 0.5961 and lr: 1e-05\n",
      "train Loss: 0.6262 and lr: 1e-05\n",
      "train Loss: 0.5913 and lr: 1e-05\n",
      "train Loss: 0.5807 and lr: 1e-05\n",
      "train Loss: 0.5773 and lr: 1e-05\n",
      "train Loss: 0.5613 and lr: 1e-05\n",
      "train Loss: 0.5513 and lr: 1e-05\n",
      "train Loss: 0.5775 and lr: 1e-05\n",
      "train Loss: 0.6072 and lr: 1e-05\n",
      "train Loss: 0.6340 and lr: 1e-05\n",
      "train Loss: 0.6478 and lr: 1e-05\n",
      "train Loss: 0.6376 and lr: 1e-05\n",
      "train Loss: 0.6249 and lr: 1e-05\n",
      "train Loss: 0.6420 and lr: 1e-05\n",
      "train Loss: 0.6512 and lr: 1e-05\n",
      "train Loss: 0.6464 and lr: 1e-05\n",
      "train Loss: 0.6620 and lr: 1e-05\n",
      "train Loss: 0.6534 and lr: 1e-05\n",
      "train Loss: 0.6491 and lr: 1e-05\n",
      "train Loss: 0.6640 and lr: 1e-05\n",
      "train Loss: 0.6556 and lr: 1e-05\n",
      "train Loss: 0.6494 and lr: 1e-05\n",
      "train Loss: 0.6423 and lr: 1e-05\n",
      "train Loss: 0.6597 and lr: 1e-05\n",
      "train Loss: 0.6710 and lr: 1e-05\n",
      "train Loss: 0.6625 and lr: 1e-05\n",
      "train Loss: 0.6561 and lr: 1e-05\n",
      "train Loss: 0.6671 and lr: 1e-05\n",
      "train Loss: 0.6751 and lr: 1e-05\n",
      "train Loss: 0.6698 and lr: 1e-05\n",
      "train Loss: 0.6676 and lr: 1e-05\n",
      "train Loss: 0.6729 and lr: 1e-05\n",
      "train Loss: 0.6663 and lr: 1e-05\n",
      "train Loss: 0.6607 and lr: 1e-05\n",
      "train Loss: 0.6669 and lr: 1e-05\n",
      "train Loss: 0.6643 and lr: 1e-05\n",
      "train Loss: 0.6603 and lr: 1e-05\n",
      "train Loss: 0.6553 and lr: 1e-05\n",
      "train Loss: 0.6538 and lr: 1e-05\n",
      "train Loss: 0.6635 and lr: 1e-05\n",
      "train Loss: 0.6601 and lr: 1e-05\n",
      "train Loss: 0.6565 and lr: 1e-05\n",
      "train Loss: 0.6639 and lr: 1e-05\n",
      "train Loss: 0.6684 and lr: 1e-05\n",
      "train Loss: 0.6651 and lr: 1e-05\n",
      "train Loss: 0.6746 and lr: 1e-05\n",
      "train Loss: 0.6732 and lr: 1e-05\n",
      "train Loss: 0.6701 and lr: 1e-05\n",
      "train Loss: 0.6682 and lr: 1e-05\n",
      "train Loss: 0.6659 and lr: 1e-05\n",
      "Step 20/30\n",
      "----------\n",
      "train Loss: 0.4401 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7799 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6937 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7542 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7513 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7544 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7116 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6700 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6579 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6539 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6344 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6180 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5998 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5834 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6007 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5966 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6123 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6027 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5961 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5955 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5982 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5950 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6099 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6175 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6140 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6197 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6138 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6259 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6329 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6310 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6398 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6559 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6621 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6585 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6531 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6586 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6541 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6512 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6493 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6456 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6429 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6513 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6462 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6461 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6504 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6465 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6436 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6523 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6492 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6523 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6518 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6490 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6451 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6475 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6440 and lr: 1.0000000000000002e-07\n",
      "Step 21/30\n",
      "----------\n",
      "train Loss: 0.4297 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6691 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5891 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5523 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6599 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7158 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6812 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7180 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6931 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6830 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6565 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6365 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6575 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6404 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6325 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6614 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6571 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6439 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6593 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6592 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6557 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6726 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6711 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6632 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6549 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6468 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6434 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6560 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6499 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6574 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6508 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6477 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6430 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6440 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6380 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6375 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6342 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6297 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6335 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6409 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6417 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6483 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6437 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6456 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6395 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6361 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6329 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6368 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6346 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6433 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6399 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6446 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6452 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6490 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6524 and lr: 1.0000000000000002e-06\n",
      "Step 22/30\n",
      "----------\n",
      "train Loss: 0.4963 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.4701 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5452 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6736 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7343 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7220 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7638 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7312 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7224 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6968 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7289 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7104 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7268 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7197 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7268 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7418 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7275 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7145 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7363 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7285 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7176 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7091 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7143 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7043 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6974 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6934 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6877 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6769 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6884 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7006 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6932 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7072 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6992 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7082 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7018 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7103 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7136 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7055 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7005 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6956 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6878 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6935 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6889 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6834 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6776 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6748 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6839 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6829 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6900 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6870 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6839 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6910 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6865 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6850 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6877 and lr: 1.0000000000000002e-06\n",
      "Step 23/30\n",
      "----------\n",
      "train Loss: 0.5107 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5125 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6187 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6135 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5767 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5786 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6431 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6308 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6222 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6613 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6391 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6613 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6729 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6626 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6889 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6834 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6771 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6929 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6819 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6963 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6872 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7016 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6866 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6797 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6740 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6656 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6579 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6485 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6395 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6310 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6234 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6224 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6225 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6214 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6177 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6145 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6246 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6204 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6271 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6391 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6488 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6440 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6393 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6469 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6524 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6573 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6661 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6604 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6649 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6696 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6733 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6717 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6690 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6632 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6611 and lr: 1.0000000000000002e-06\n",
      "Step 24/30\n",
      "----------\n",
      "train Loss: 0.4687 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.4587 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5410 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6349 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6757 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7421 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7085 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6822 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.7181 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6929 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6730 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6576 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6798 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6637 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6464 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6640 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6575 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6692 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6568 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6473 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6352 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6243 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6237 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6179 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6101 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6067 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6022 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.5980 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6087 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6029 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6138 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6239 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6305 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6257 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6240 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6378 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6320 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6291 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6382 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6342 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6281 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6340 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6300 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6280 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6324 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6433 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6370 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6340 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6308 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6378 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6350 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6332 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6374 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6413 and lr: 1.0000000000000002e-06\n",
      "train Loss: 0.6387 and lr: 1.0000000000000002e-06\n",
      "Step 25/30\n",
      "----------\n",
      "train Loss: 0.4941 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5072 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5106 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5284 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5094 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.4975 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5810 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5654 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.5996 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6330 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6671 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6942 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6793 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6771 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6692 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6563 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6625 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6684 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6582 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6503 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6465 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6385 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6359 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6323 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6315 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6465 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6573 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6644 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6585 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6697 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6664 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6600 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6528 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6457 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6399 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6418 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6395 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6372 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6339 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6410 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6377 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6484 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6446 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6489 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6444 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6411 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6387 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6360 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6419 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6375 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6417 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6503 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6571 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6545 and lr: 1.0000000000000004e-08\n",
      "train Loss: 0.6612 and lr: 1.0000000000000004e-08\n",
      "Step 26/30\n",
      "----------\n",
      "train Loss: 0.9466 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.9641 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.9645 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.8564 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.8572 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.8140 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7916 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7990 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7613 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7341 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7534 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7400 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7481 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7267 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7081 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7008 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6964 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7143 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7337 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7382 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7243 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7379 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7523 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7582 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7468 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7419 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7324 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7200 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7341 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7249 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7192 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7097 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7216 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7173 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7223 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7181 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7109 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7169 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7116 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7086 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7030 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6970 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7055 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7020 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6949 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6887 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6845 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6797 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6748 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6748 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6805 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6784 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6729 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6695 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6731 and lr: 1.0000000000000002e-07\n",
      "Step 27/30\n",
      "----------\n",
      "train Loss: 0.4020 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.3904 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4134 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4189 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4420 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4487 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4597 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4772 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4811 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5082 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4990 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4953 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5070 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5288 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5486 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5523 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5424 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5402 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5595 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5559 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5713 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5750 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5750 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5904 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5877 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6087 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6225 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6197 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6153 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6070 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6211 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6315 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6277 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6273 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6351 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6323 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6324 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6260 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6221 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6221 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6184 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6220 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6199 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6241 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6212 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6313 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6374 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6326 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6291 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6359 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6453 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6503 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6487 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6526 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6560 and lr: 1.0000000000000002e-07\n",
      "Step 28/30\n",
      "----------\n",
      "train Loss: 1.0313 and lr: 1.0000000000000002e-07\n",
      "train Loss: 1.0292 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.8285 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7161 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7357 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7724 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7772 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7381 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7219 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6980 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6763 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6952 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7030 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6790 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6595 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6497 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6440 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6749 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6897 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6979 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6901 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6807 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6684 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6652 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6584 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6529 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6442 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6442 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6395 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6370 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6362 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6476 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6394 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6379 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6476 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6570 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6532 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6614 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6581 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6566 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6538 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6502 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6469 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6416 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6508 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6575 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6534 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6495 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6561 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6532 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6513 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6491 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6611 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6657 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6698 and lr: 1.0000000000000002e-07\n",
      "Step 29/30\n",
      "----------\n",
      "train Loss: 0.4895 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4569 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.4776 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5104 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5189 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5082 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5795 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6387 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6227 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6176 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6088 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6084 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6005 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5874 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.5839 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6059 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6277 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6204 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6416 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6531 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6410 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6372 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6292 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6456 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6396 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6612 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6552 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6640 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6770 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6691 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6813 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6922 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6992 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.7062 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6989 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6929 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6850 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6927 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6903 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6865 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6852 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6812 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6859 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6906 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6882 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6822 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6777 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6754 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6699 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6784 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6762 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6740 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6809 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6869 and lr: 1.0000000000000002e-07\n",
      "train Loss: 0.6834 and lr: 1.0000000000000002e-07\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3ca3b92298fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-e53a6372d8a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model_withname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e53a6372d8a3>\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, model, optimizer, scheduler, epoch, save_model)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;34m'scheduler_state'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 'epoch' : epoch+1}\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_%d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0msave_model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tar'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not NoneType"
     ]
    }
   ],
   "source": [
    "a.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
