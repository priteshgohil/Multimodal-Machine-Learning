{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author : Priteshkumar Gohil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "if('/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path):\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base class for dataloader vision.py\n",
    "\n",
    "class VisionDataset(data.Dataset):\n",
    "    _repr_indent = 4\n",
    "\n",
    "    def __init__(self, root, transforms=None, transform=None, target_transform=None):\n",
    "        if isinstance(root, torch._six.string_classes):\n",
    "            root = os.path.expanduser(root)\n",
    "        self.root = root\n",
    "\n",
    "        has_transforms = transforms is not None\n",
    "        has_separate_transform = transform is not None or target_transform is not None\n",
    "        if has_transforms and has_separate_transform:\n",
    "            raise ValueError(\"Only transforms or transform/target_transform can \"\n",
    "                             \"be passed as argument\")\n",
    "\n",
    "        # for backwards-compatibility\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        if has_separate_transform:\n",
    "            transforms = StandardTransform(transform, target_transform)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self):\n",
    "        head = \"Dataset \" + self.__class__.__name__\n",
    "        body = [\"Number of datapoints: {}\".format(self.__len__())]\n",
    "        if self.root is not None:\n",
    "            body.append(\"Root location: {}\".format(self.root))\n",
    "        body += self.extra_repr().splitlines()\n",
    "        if hasattr(self, \"transforms\") and self.transforms is not None:\n",
    "            body += [repr(self.transforms)]\n",
    "        lines = [head] + [\" \" * self._repr_indent + line for line in body]\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "    def _format_transform_repr(self, transform, head):\n",
    "        lines = transform.__repr__().splitlines()\n",
    "        return ([\"{}{}\".format(head, lines[0])] +\n",
    "                [\"{}{}\".format(\" \" * len(head), line) for line in lines[1:]])\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "class StandardTransform(object):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __call__(self, input, target):\n",
    "        if self.transform is not None:\n",
    "            input = self.transform(input)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return input, target\n",
    "\n",
    "    def _format_transform_repr(self, transform, head):\n",
    "        lines = transform.__repr__().splitlines()\n",
    "        return ([\"{}{}\".format(head, lines[0])] +\n",
    "                [\"{}{}\".format(\" \" * len(head), line) for line in lines[1:]])\n",
    "\n",
    "    def __repr__(self):\n",
    "        body = [self.__class__.__name__]\n",
    "        if self.transform is not None:\n",
    "            body += self._format_transform_repr(self.transform,\n",
    "                                                \"Transform: \")\n",
    "        if self.target_transform is not None:\n",
    "            body += self._format_transform_repr(self.target_transform,\n",
    "                                                \"Target transform: \")\n",
    "\n",
    "        return '\\n'.join(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def has_file_allowed_extension(filename, extensions):\n",
    "    \"\"\"Checks if a file is an allowed extension.\n",
    "    Args:\n",
    "        filename (string): path to a file\n",
    "        extensions (tuple of strings): extensions to consider (lowercase)\n",
    "    Returns:\n",
    "        bool: True if the filename ends with one of given extensions\n",
    "    \"\"\"\n",
    "    return filename.lower().endswith(extensions)\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Checks if a file is an allowed image extension.\n",
    "    Args:\n",
    "        filename (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return has_file_allowed_extension(filename, IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def make_dataset(dir, class_to_idx, extensions=None, is_valid_file=None):\n",
    "    images = []\n",
    "    # dir = /media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/\n",
    "    dir = os.path.expanduser(dir)\n",
    "    if not ((extensions is None) ^ (is_valid_file is None)):\n",
    "        raise ValueError(\"Both extensions and is_valid_file cannot be None or not None at the same time\")\n",
    "    if extensions is not None:\n",
    "        def is_valid_file(x):\n",
    "            return has_file_allowed_extension(x, extensions)\n",
    "    for target in sorted(class_to_idx.keys()):\n",
    "        # d = /media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Cheez\n",
    "        d = os.path.join(dir, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            # root = /media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Cheez\n",
    "            #        /media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Cheez/100_432\n",
    "            #        /media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Cheez/100_432/right\n",
    "            #        /media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Cheez/100_432/right/0\n",
    "            # fnames = []\n",
    "            # fnames = []\n",
    "            # fnames = []\n",
    "            # fnames = ['front_0.jpg', 'front_1.jpg', 'front_depth.mp4', 'front_depth0.mp4', 'front_rgb.mp4', \n",
    "            #           'label.txt', 'left_0.jpg', 'left_1.jpg', 'left_rgb.mp4', 'pos.txt', 'tactile.txt']\n",
    "            image_path = None\n",
    "            tactile_path = None\n",
    "            label_path = None\n",
    "            video_path = None\n",
    "            left_video_path = None\n",
    "            pos_path = None\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "                if(path.lower().endswith(extensions[0])):\n",
    "                    image_path = path\n",
    "                elif(path.lower().endswith(extensions[1])):\n",
    "                    tactile_path = path\n",
    "                elif(path.lower().endswith(extensions[2])):\n",
    "                    label_path = path\n",
    "                elif(path.lower().endswith(extensions[3])):\n",
    "                    video_path = path\n",
    "                elif(path.lower().endswith(extensions[4])):\n",
    "                    left_video_path = path\n",
    "                elif(path.lower().endswith(extensions[5])):\n",
    "                    pos_path = path\n",
    "            # return data iff it contains all the 4 files.\n",
    "            # If you wants to return irrespective of video modify the code\n",
    "            if((image_path and tactile_path and label_path and video_path and left_video_path and pos_path) is not None):\n",
    "                item = (image_path,tactile_path,label_path,video_path, left_video_path,pos_path, np.loadtxt(label_path)[3])\n",
    "                images.append(item)\n",
    "    return images\n",
    "\n",
    "\n",
    "class VisualTactile(VisionDataset):\n",
    "    \"\"\"A generic data loader where the samples are arranged in this way: ::\n",
    "        root/class_x/xxx.ext\n",
    "        root/class_x/xxy.ext\n",
    "        root/class_x/xxz.ext\n",
    "        root/class_y/123.ext\n",
    "        root/class_y/nsdf3.ext\n",
    "        root/class_y/asd932_.ext\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        loader (callable): A function to load a sample given its path.\n",
    "        extensions (tuple[string]): A list of allowed extensions.\n",
    "            both extensions and is_valid_file should not be passed.\n",
    "        transform (callable, optional): A function/transform that takes in\n",
    "            a sample and returns a transformed version.\n",
    "            E.g, ``transforms.RandomCrop`` for images.\n",
    "        target_transform (callable, optional): A function/transform that takes\n",
    "            in the target and transforms it.\n",
    "        is_valid_file (callable, optional): A function that takes path of an Image file\n",
    "            and check if the file is a valid_file (used to check of corrupt files)\n",
    "            both extensions and is_valid_file should not be passed.\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        samples (list): List of (sample path, class_index) tuples\n",
    "        targets (list): The class_index value for each image in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, loader, extensions=None, transform=None, target_transform=None, is_valid_file=None):\n",
    "        super(VisualTactile, self).__init__(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # classes = name of the folder\n",
    "        # class_to_idx = dictionary with class name(folder name) and index\n",
    "        classes, class_to_idx = self._find_classes(self.root)\n",
    "        samples = make_dataset(self.root, class_to_idx, extensions, is_valid_file)\n",
    "#         print(samples)\n",
    "        if len(samples) == 0:\n",
    "            raise (RuntimeError(\"Found 0 files in subfolders of: \" + self.root + \"\\n\"\n",
    "                                \"Supported extensions are: \" + \",\".join(extensions)))\n",
    "\n",
    "        self.loader = loader\n",
    "        self.extensions = extensions\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.samples = samples\n",
    "        self.targets = [s[1] for s in samples]\n",
    "\n",
    "    def _find_classes(self, dir):\n",
    "        \"\"\"\n",
    "        Finds the class folders in a dataset.\n",
    "        Args:\n",
    "            dir (string): Root directory path.\n",
    "        Returns:\n",
    "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
    "        Ensures:\n",
    "            No class is a subdirectory of another.\n",
    "        \"\"\"\n",
    "        if sys.version_info >= (3, 5):\n",
    "            # Faster and available in Python 3.5 and above\n",
    "            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        else:\n",
    "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (sample, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        image_path, tactile_path, label_path, video_path, left_video_path, pos_path, target = self.samples[index]\n",
    "        sample_image = self.loader(image_path)\n",
    "        sample_tactile = tactile_loader(tactile_path)\n",
    "        sample_lable = label_loader(label_path)\n",
    "        sample_video = vid_loader(video_path)\n",
    "        sample_left_video = vid_loader(left_video_path)\n",
    "        sample_pos = tactile_loader(pos_path)\n",
    "        if self.transform is not None:\n",
    "            sample_image = self.transform(sample_image)\n",
    "            sample_tactile = self.transform(sample_tactile)\n",
    "            sample_lable = self.transform(sample_lable)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample_image, sample_tactile, sample_lable, sample_video, sample_left_video, sample_pos, target\n",
    "#         return sample_image, sample_tactile, sample_lable, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "# IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "# Select only these items in dataset\n",
    "# IMG_EXTENSIONS = ('front_0.jpg')\n",
    "IMG_EXTENSIONS = ('front_0.jpg','tactile.txt','label.txt','front_rgb.mp4','left_rgb.mp4', 'pos.txt')\n",
    "# TAC_EXTENSIONS = ('tactile.txt')\n",
    "# LAB_EXTENSIONS = ('label.txt')\n",
    "# VID_EXTENSIONS = ('front_rgb.mp4')\n",
    "\n",
    "def tactile_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    up_samples=24*18\n",
    "    with open(path, 'rb') as f:\n",
    "        tactile_frame = pd.read_csv(f,delimiter=' ', header=None)\n",
    "        tactile = tactile_frame.as_matrix()\n",
    "        tactile = tactile.astype('float')\n",
    "        tactile = signal.resample(tactile,up_samples)\n",
    "        return tactile #to get samples equal to the video frames, make length variable in vid_loader global and\n",
    "                        #then tactile[:lenth]\n",
    "\n",
    "def label_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        return np.loadtxt(f)\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def vid_loader(path):\n",
    "    print(path)\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    required_frames = 64\n",
    "    frame_output = 5\n",
    "    # 18x18 = 324  frames in total \n",
    "    length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"length\",length)\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    print(\"FPS\", fps )\n",
    "    duration = length / fps\n",
    "    print(\"duration\",duration)\n",
    "\n",
    "    images = []\n",
    "    while success:\n",
    "        if((count%5)==0 and (len(images)<required_frames)):\n",
    "#             images.append(image)\n",
    "            images.append(Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)))#for PIL RGB image\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    missing_frames = required_frames - len(images)\n",
    "    if(missing_frames):\n",
    "        remove_element = (missing_frames//frame_output)+1\n",
    "        del images[-remove_element:]\n",
    "        vidcap = cv2.VideoCapture(path)\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, length-missing_frames-1)\n",
    "        success,image = vidcap.read()\n",
    "        while success:\n",
    "#                 images.append(image) #BGR Image\n",
    "#                 images.append(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)) #for RGB image\n",
    "            images.append(Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)))#for PIL RGB image\n",
    "            success,image = vidcap.read()\n",
    "    return images\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "class ImageFolder(VisualTactile):\n",
    "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "        is_valid_file (callable, optional): A function that takes path of an Image file\n",
    "            and check if the file is a valid_file (used to check of corrupt files)\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                 loader=default_loader, is_valid_file=None):\n",
    "        super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                          transform=transform,\n",
    "                                          target_transform=target_transform,\n",
    "                                          is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Coffeecup/100_843/back/0/front_rgb.mp4\n",
      "length 339\n",
      "FPS 18\n",
      "duration 18.833333333333332\n",
      "/media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/Coffeecup/100_843/back/0/left_rgb.mp4\n",
      "length 339\n",
      "FPS 18\n",
      "duration 18.833333333333332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(432, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/media/pritesh/Entertainment/Visual-Tactile_Dataset/dataset/\"\n",
    "tv_dataset = ImageFolder(root=path)\n",
    "# a=tv_dataset[150] \n",
    "# a[3]\n",
    "tv_dataset[150][1].shape\n",
    "# tv_dataset[150][4][20]\n",
    "# for i in a:\n",
    "#     cv2.imshow(\"im\", a)\n",
    "#     cv2.waitKey(200)\n",
    "# cv2.destroyAllWindows()\n",
    "# a[0].shape\n",
    "## or you can use imagefolder to see data\n",
    "# tv_dataset.samples[100]\n",
    "\n",
    "## To check the to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
